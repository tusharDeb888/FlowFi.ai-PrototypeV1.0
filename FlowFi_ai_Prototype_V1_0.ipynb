{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOxI79iWlYzCh0jefaCwgk0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tusharDeb888/FlowFi.ai-PrototypeV1.0/blob/main/FlowFi_ai_Prototype_V1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install dependencies"
      ],
      "metadata": {
        "id": "UcCKe1P5F77U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOdmRaGvD8AR"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio pandas plotly\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q langchain langchain_community faiss-cpu sentence-transformers transformers torch soundfile librosa accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "5ZWmwoTEGGL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import tempfile\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "from typing import Optional, List, Tuple, Dict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import gradio as gr\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import whisper\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from transformers import pipeline as hf_pipeline"
      ],
      "metadata": {
        "id": "BTQMIeYtGFct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model & RAG Configuration"
      ],
      "metadata": {
        "id": "sNRtjVlyGG7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model file config.\n",
        "DATA_FILE = \"tracker_data.json\"\n",
        "VECTOR_DIR = \"faiss_index\"\n",
        "WHISPER_MODEL = \"base\"\n",
        "FLAN_MODEL = \"google/flan-t5-base\"\n",
        "\n",
        "# RAG config.\n",
        "EMB_MODEL = \"BAAI/bge-base-en-v1.5\"\n",
        "TARGET_SR = 16000\n",
        "\n",
        "# Silence HuggingFace parallelism warning\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "metadata": {
        "id": "gtdgDYzgGHky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Application's memory system\n",
        "\n",
        "* DATA_FILE (tracker_data.json)\n",
        "    * This is the physical file folder, where all the expense and budget data is permanently stored on disk when the app isn't running.\n",
        "* app_data:\n",
        "    * It's the live, in-memory version of the data that the application actively works with (reads from, adds to, deletes from).\n",
        "* load_data():\n",
        "    * This is the action of getting the folder from the dir at the start of the app.\n",
        "\n",
        "* save_data():\n",
        "    * This is the action of putting the folder back into the dir after making changes."
      ],
      "metadata": {
        "id": "_HWctD-vHM2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data() -> Dict:\n",
        "    \"\"\"Loads data from the JSON file, ensuring expenses have unique IDs.\"\"\"\n",
        "    if os.path.exists(DATA_FILE):\n",
        "        with open(DATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "        for expense in data.get(\"expenses\", []):\n",
        "            if \"id\" not in expense:\n",
        "                expense[\"id\"] = str(uuid.uuid4())\n",
        "        return data\n",
        "    return {\"expenses\": [], \"budgets\": {}}\n",
        "\n",
        "def save_data(data: Dict):\n",
        "    \"\"\"Saves data to the JSON file.\"\"\"\n",
        "    with open(DATA_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "app_data = load_data()"
      ],
      "metadata": {
        "id": "TFQzanPjHNVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load AI Models"
      ],
      "metadata": {
        "id": "wYeZDQ8BLacJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading AI models... This might take a few minutes.\")\n",
        "try:\n",
        "    asr_model = whisper.load_model(WHISPER_MODEL)\n",
        "    print(\"Whisper model loaded Successfully.....\")\n",
        "\n",
        "    device = 0 if \"CUDA_VISIBLE_DEVICES\" in os.environ else -1\n",
        "    flan_pipe = hf_pipeline(\"text2text-generation\", model=FLAN_MODEL, device=device, max_new_tokens=256)\n",
        "    llm = HuggingFacePipeline(pipeline=flan_pipe)\n",
        "    print(\"Flan-T5 LLM loaded Successfully.....\")\n",
        "\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=EMB_MODEL)\n",
        "    print(\"Embeddings model loaded Successfully.....\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading models: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "jW6z4OzgLa2M",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speech to Text Setup"
      ],
      "metadata": {
        "id": "8L_7rs-oL57z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_numpy_audio_to_wav(numpy_audio, target_sr=TARGET_SR) -> str:\n",
        "    if numpy_audio is None: raise ValueError(\"No audio provided\")\n",
        "    sr, audio = numpy_audio\n",
        "    if not np.issubdtype(audio.dtype, np.floating):\n",
        "        audio = audio.astype(np.float32) / np.iinfo(audio.dtype).max\n",
        "    if audio.ndim > 1: audio = np.mean(audio, axis=1)\n",
        "    if sr != target_sr:\n",
        "        audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
        "    tmp_wav = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
        "    sf.write(tmp_wav.name, audio, target_sr)\n",
        "    return tmp_wav.name\n",
        "\n",
        "def parse_amount(text: str) -> Optional[float]:\n",
        "    \"\"\"abstract amount from the audio\"\"\"\n",
        "    match = re.search(r\"(\\d+(?:[.,]\\d+)?)\", text)\n",
        "    return float(match.group(1).replace(\",\", \".\")) if match else None\n",
        "\n",
        "def parse_category(text: str) -> str:\n",
        "    \"\"\"abstract category from the audio\"\"\"\n",
        "    text_l = text.lower()\n",
        "    keywords = {\n",
        "        \"Food\": [\"food\", \"restaurant\", \"lunch\", \"dinner\", \"snack\", \"coffee\"],\n",
        "        \"Groceries\": [\"groceries\", \"supermarket\", \"market\"],\n",
        "        \"Transport\": [\"taxi\", \"uber\", \"bus\", \"train\", \"metro\", \"fuel\"],\n",
        "        \"Utilities\": [\"bill\", \"electricity\", \"internet\", \"phone\", \"water\"],\n",
        "        \"Rent\": [\"rent\", \"mortgage\"],\n",
        "        \"Shopping\": [\"shopping\", \"clothes\", \"electronics\", \"store\"],\n",
        "        \"Entertainment\": [\"movie\", \"concert\", \"game\", \"netflix\"],\n",
        "    }\n",
        "    for cat, kws in keywords.items():\n",
        "        if any(kw in text_l for kw in kws):\n",
        "            return cat\n",
        "    return \"Misc\""
      ],
      "metadata": {
        "id": "rBqeLavsL6VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG Implementation\n",
        "\n"
      ],
      "metadata": {
        "id": "VWQH0te6MqOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_TEMPLATE = \"\"\"You are an expert financial assistant. Use the following expense records to answer the user's question concisely. Provide calculations if helpful. If you don't find the answer in the records, say \"I could not find any relevant expenses for your question.ask me like total spent on rent..\"\n",
        "\n",
        "Context (Expense Records):\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\"\"\"\n",
        "QA_PROMPT = PromptTemplate(template=PROMPT_TEMPLATE, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "_RAG_COMPONENTS = {\"retriever\": None, \"chain\": None}\n",
        "\n",
        "def build_vector_store():\n",
        "    \"\"\"Builds and saves the FAISS vector store from the latest expense data.\"\"\"\n",
        "\n",
        "    global _RAG_COMPONENTS\n",
        "    expenses = app_data.get(\"expenses\", [])\n",
        "    if not expenses:\n",
        "        _RAG_COMPONENTS = {\"retriever\": None, \"chain\": None}\n",
        "        return\n",
        "\n",
        "    texts = []\n",
        "    for e in expenses:\n",
        "\n",
        "        full_text = e.get('text', 'no description')\n",
        "        doc = f\"On {e.get('date')}, an expense of Rs. {e.get('amount', 0.0):.2f} was recorded in the '{e.get('category', 'Misc')}' category. The description is: '{full_text}'.\"\n",
        "        texts.append(doc)\n",
        "\n",
        "    store = FAISS.from_texts(texts, embeddings)\n",
        "    store.save_local(VECTOR_DIR)\n",
        "\n",
        "\n",
        "    _RAG_COMPONENTS = {\"retriever\": None, \"chain\": None}\n",
        "    print(\"‚úÖ Vector store rebuilt successfully.\")\n",
        "\n",
        "def get_rag_components():\n",
        "    \"\"\"Loads the vector store and initializes the RAG chain if not already loaded.\"\"\"\n",
        "    if _RAG_COMPONENTS.get(\"chain\") is None:\n",
        "        if not os.path.exists(VECTOR_DIR):\n",
        "            return None, None\n",
        "\n",
        "        store = FAISS.load_local(VECTOR_DIR, embeddings, allow_dangerous_deserialization=True)\n",
        "        retriever = store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
        "\n",
        "        # Use the more controllable load_qa_chain with our custom prompt\n",
        "        chain = load_qa_chain(llm=llm, chain_type=\"stuff\", prompt=QA_PROMPT)\n",
        "\n",
        "        _RAG_COMPONENTS[\"retriever\"] = retriever\n",
        "        _RAG_COMPONENTS[\"chain\"] = chain\n",
        "        print(\"‚úÖ RAG chain initialized.\")\n",
        "\n",
        "    return _RAG_COMPONENTS[\"retriever\"], _RAG_COMPONENTS[\"chain\"]\n",
        "\n",
        "# Initialize vector store on startup\n",
        "build_vector_store()\n",
        "\n",
        "def rag_chat_enhanced(user_input: str, chat_history: List):\n",
        "    chat_history = chat_history or []\n",
        "\n",
        "    # Keep the fast, rule-based approach for simple math queries\n",
        "    total_match = re.search(r\"(?:total|sum|how much.*on)\\s+([\\w\\s]+)\", user_input, re.IGNORECASE)\n",
        "    list_match = re.search(r\"(?:show|list|display)\\s+(?:all\\s+)?([\\w\\s]+)\\s+expenses\", user_input, re.IGNORECASE)\n",
        "\n",
        "    df = get_expenses_df()\n",
        "    if total_match:\n",
        "        category = total_match.group(1).strip().capitalize()\n",
        "        cat_df = df[df['category'].str.contains(category, case=False)]\n",
        "        if not cat_df.empty:\n",
        "            total = cat_df['amount'].sum()\n",
        "            answer = f\"The total spending on **{category}** is **‚Çπ{total:,.2f}**.\"\n",
        "            chat_history.append((user_input, answer))\n",
        "            return chat_history, None, \"\"\n",
        "    elif list_match:\n",
        "        category = list_match.group(1).strip().capitalize()\n",
        "        cat_df = df[df['category'].str.contains(category, case=False)]\n",
        "        if not cat_df.empty:\n",
        "            answer = f\"Here are all expenses for **{category}**:\"\n",
        "            chat_history.append((user_input, answer))\n",
        "            return chat_history, cat_df[['date', 'category', 'amount', 'text']], \"\"\n",
        "\n",
        "    # --- RAG IMPROVEMENT 3: USE THE NEW, MORE POWERFUL CHAIN ---\n",
        "    # Fallback to the LLM RAG chain for complex, semantic questions\n",
        "    retriever, chain = get_rag_components()\n",
        "    if not retriever or not chain:\n",
        "        answer = \"The AI is not ready. Please add at least one expense to activate it.\"\n",
        "        chat_history.append((user_input, answer))\n",
        "        return chat_history, None, \"\"\n",
        "\n",
        "    # 1. Retrieve relevant documents from the vector store\n",
        "    relevant_docs = retriever.invoke(user_input)\n",
        "    if not relevant_docs:\n",
        "        answer = \"I couldn't find any expenses related to your question.\"\n",
        "        chat_history.append((user_input, answer))\n",
        "        return chat_history, None, \"\"\n",
        "\n",
        "    # 2. Call the LLM chain with the retrieved docs and the question\n",
        "    result = chain.invoke({\"input_documents\": relevant_docs, \"question\": user_input}, return_only_outputs=True)\n",
        "    answer = result.get(\"output_text\", \"Sorry, I had trouble finding an answer.\")\n",
        "\n",
        "    chat_history.append((user_input, answer))\n",
        "    return chat_history, None, \"\""
      ],
      "metadata": {
        "id": "rGPQm3cUMqng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Processing & Visualization"
      ],
      "metadata": {
        "id": "fkLbLPWFNimu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_expenses_df() -> pd.DataFrame:\n",
        "    expenses = app_data.get(\"expenses\", [])\n",
        "    if not expenses:\n",
        "        return pd.DataFrame(columns=[\"id\", \"date\", \"category\", \"amount\", \"text\"])\n",
        "    df = pd.DataFrame(expenses)\n",
        "    df[\"amount\"] = pd.to_numeric(df[\"amount\"], errors=\"coerce\").fillna(0.0)\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    return df.sort_values(by=\"date\", ascending=False)\n",
        "\n",
        "def update_dashboard_cards(df: pd.DataFrame):\n",
        "    if df.empty: return \"‚Çπ0.00\", \"‚Çπ0.00\"\n",
        "    total_spend = df[\"amount\"].sum()\n",
        "    avg_transaction = df[\"amount\"].mean()\n",
        "    return f\"‚Çπ{total_spend:,.2f}\", f\"‚Çπ{avg_transaction:,.2f}\"\n",
        "\n",
        "def update_visualizations(df: pd.DataFrame):\n",
        "    if df.empty: return None, None, None\n",
        "    pie_fig = px.pie(df, values=\"amount\", names=\"category\", title=\"Expense Breakdown\", hole=0.3)\n",
        "    bar_df = df.groupby(\"category\")[\"amount\"].sum().reset_index().sort_values(\"amount\", ascending=False)\n",
        "    bar_fig = px.bar(bar_df, x=\"category\", y=\"amount\", title=\"Spending by Category\", text_auto='.2s')\n",
        "    line_df = df.groupby(df['date'].dt.date)[\"amount\"].sum().reset_index()\n",
        "    line_fig = px.line(line_df, x=\"date\", y=\"amount\", title=\"Spending Over Time\", markers=True)\n",
        "    return pie_fig, bar_fig, line_fig"
      ],
      "metadata": {
        "id": "NdfbgI-DNi9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CRUD Operations"
      ],
      "metadata": {
        "id": "O-ARC9TeNqpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def refresh_all_components():\n",
        "    df = get_expenses_df()\n",
        "    total_spend, avg_txn = update_dashboard_cards(df)\n",
        "    pie, bar, line = update_visualizations(df)\n",
        "    current_month_str = datetime.now().strftime(\"%Y-%m\")\n",
        "    alerts = check_budget_alerts_for_month(current_month_str)\n",
        "    alert_text = \"\\n\".join(alerts) if alerts else \"No budget alerts.\"\n",
        "    return df, total_spend, avg_txn, pie, bar, line, alert_text\n",
        "\n",
        "def add_expense(text: str, amount: float, category: str, date_str: str):\n",
        "    if not amount or not category: raise gr.Error(\"Amount and Category are required.\")\n",
        "    entry = {\"id\": str(uuid.uuid4()), \"date\": date_str or datetime.now().strftime(\"%Y-%m-%d\"), \"category\": category.strip().capitalize(), \"amount\": float(amount), \"text\": text.strip()}\n",
        "    app_data[\"expenses\"].append(entry)\n",
        "    save_data(app_data)\n",
        "    build_vector_store()\n",
        "    gr.Info(\"‚úÖ Manual expense added.\")\n",
        "    return refresh_all_components()\n",
        "\n",
        "def add_expense_voice(audio_input):\n",
        "    if audio_input is None: raise gr.Error(\"No audio recorded. Please record your expense.\")\n",
        "    wav_path = save_numpy_audio_to_wav(audio_input)\n",
        "    transcription = asr_model.transcribe(wav_path, fp16=False)[\"text\"]\n",
        "    amount = parse_amount(transcription)\n",
        "    category = parse_category(transcription)\n",
        "    if amount is None:\n",
        "        gr.Warning(\"Could not detect an amount in audio. Please add it manually.\")\n",
        "        return # Or pre-fill form\n",
        "    add_expense(transcription, amount, category, datetime.now().strftime(\"%Y-%m-%d\"))\n",
        "    gr.Info(f\"‚úÖ Voice expense added: {transcription}\")\n",
        "    return refresh_all_components()\n",
        "\n",
        "def update_expense(expense_id: str, date: str, category: str, amount: float, text: str):\n",
        "    if not expense_id: raise gr.Error(\"No expense selected to update.\")\n",
        "    for expense in app_data[\"expenses\"]:\n",
        "        if expense[\"id\"] == expense_id:\n",
        "            expense.update({\"date\": date, \"category\": category.strip().capitalize(), \"amount\": float(amount), \"text\": text.strip()})\n",
        "            break\n",
        "    save_data(app_data)\n",
        "    build_vector_store()\n",
        "    gr.Info(\"‚úÖ Expense updated successfully!\")\n",
        "    return refresh_all_components()\n",
        "\n",
        "def delete_expense(expense_id: str):\n",
        "    if not expense_id: raise gr.Error(\"No expense selected to delete.\")\n",
        "    app_data[\"expenses\"] = [exp for exp in app_data[\"expenses\"] if exp[\"id\"] != expense_id]\n",
        "    save_data(app_data)\n",
        "    build_vector_store()\n",
        "    gr.Info(\"üóëÔ∏è Expense deleted successfully!\")\n",
        "    return *refresh_all_components(), \"\", \"\", \"\", \"\", \"\"\n"
      ],
      "metadata": {
        "id": "WEhGQgbwNq8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Budget Logic"
      ],
      "metadata": {
        "id": "EN7lardnN83x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_budget(category: str, amount: float):\n",
        "    if not category or amount is None or float(amount) <= 0: raise gr.Error(\"Valid category and positive budget required.\")\n",
        "    app_data.setdefault(\"budgets\", {})[category.strip().capitalize()] = float(amount)\n",
        "    save_data(app_data)\n",
        "    budgets_df = pd.DataFrame(list(app_data.get(\"budgets\", {}).items()), columns=[\"Category\", \"Budget\"])\n",
        "    gr.Info(f\"Budget set for {category.capitalize()}: ‚Çπ{amount:,.2f}\")\n",
        "    return budgets_df\n",
        "\n",
        "def check_budget_alerts_for_month(year_month: str) -> List[str]:\n",
        "    alerts = []\n",
        "    df = get_expenses_df()\n",
        "    if df.empty: return []\n",
        "    df[\"ym\"] = df[\"date\"].dt.strftime(\"%Y-%m\")\n",
        "    month_df = df[df[\"ym\"] == year_month]\n",
        "    if month_df.empty: return []\n",
        "    sums_by_cat = month_df.groupby(\"category\")[\"amount\"].sum().to_dict()\n",
        "    budgets = app_data.get(\"budgets\", {})\n",
        "    for cat, budget_amount in budgets.items():\n",
        "        spent = sums_by_cat.get(cat, 0.0)\n",
        "        if spent >= budget_amount:\n",
        "            alerts.append(f\"üö® Budget EXCEEDED for {cat}: Spent ‚Çπ{spent:,.2f} of ‚Çπ{budget_amount:,.2f}\")\n",
        "        elif spent >= 0.8 * budget_amount:\n",
        "            alerts.append(f\"‚ö†Ô∏è Nearing budget for {cat}: Spent ‚Çπ{spent:,.2f} of ‚Çπ{budget_amount:,.2f} ({(spent/budget_amount):.0%})\")\n",
        "    return alerts"
      ],
      "metadata": {
        "id": "3P-4DBCkN9Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gradio UI"
      ],
      "metadata": {
        "id": "Fc_YRGvmOlZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"# AI Smart Expense Manager\") as demo:\n",
        "    gr.Markdown(\"FlowFi.ai Prototype V1.0\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"Dashboard\"):\n",
        "            with gr.Row():\n",
        "                total_spend_card = gr.Textbox(label=\"üí∞ Total Expenses\", interactive=False)\n",
        "                avg_txn_card = gr.Textbox(label=\"üìä Average Transaction\", interactive=False)\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=1):\n",
        "                    gr.Markdown(\"### Add New Expense\")\n",
        "                    with gr.Tabs():\n",
        "                        with gr.TabItem(\"üé§ Voice\"):\n",
        "                            mic_audio = gr.Audio(sources=[\"microphone\"], type=\"numpy\", label=\"Record your expense\")\n",
        "                            add_voice_btn = gr.Button(\"Add from Voice\", variant=\"primary\")\n",
        "                        with gr.TabItem(\"‚úçÔ∏è Manual\"):\n",
        "                            m_text = gr.Textbox(label=\"Description\")\n",
        "                            m_amount = gr.Number(label=\"Amount\")\n",
        "                            m_cat = gr.Textbox(label=\"Category\")\n",
        "                            m_date = gr.Textbox(label=\"Date\", value=datetime.now().strftime(\"%Y-%m-%d\"))\n",
        "                            add_manual_btn = gr.Button(\"Add Manually\", variant=\"primary\")\n",
        "                    with gr.Accordion(\"Set Monthly Budget\", open=False):\n",
        "                        b_category = gr.Textbox(label=\"Category\")\n",
        "                        b_amount = gr.Number(label=\"Monthly Budget Amount\")\n",
        "                        set_budget_btn = gr.Button(\"Set Budget\")\n",
        "                        current_budgets_df = gr.DataFrame(value=pd.DataFrame(list(app_data.get(\"budgets\", {}).items()), columns=[\"Category\", \"Budget\"]), interactive=False)\n",
        "                    budget_alerts_box = gr.Textbox(label=\"üö® Budget Alerts\", interactive=False, lines=3)\n",
        "                with gr.Column(scale=2):\n",
        "                    gr.Markdown(\"### All Expenses\")\n",
        "                    expense_df_display = gr.DataFrame(value=get_expenses_df, headers=[\"ID\", \"Date\", \"Category\", \"Amount\", \"Description\"], interactive=False)\n",
        "                    gr.Markdown(\"### Edit Selected Expense\")\n",
        "                    edit_id = gr.Textbox(label=\"Expense ID\", interactive=False)\n",
        "                    edit_date = gr.Textbox(label=\"Date\")\n",
        "                    edit_cat = gr.Textbox(label=\"Category\")\n",
        "                    edit_amount = gr.Number(label=\"Amount\")\n",
        "                    edit_text = gr.Textbox(label=\"Description\")\n",
        "                    with gr.Row():\n",
        "                        update_btn = gr.Button(\"Update Expense\", variant=\"primary\")\n",
        "                        delete_btn = gr.Button(\"Delete Expense\", variant=\"stop\")\n",
        "\n",
        "        with gr.TabItem(\"Analysis & AI Chat\"):\n",
        "            gr.Markdown(\"## üìä Visual Analysis\")\n",
        "            with gr.Row(): pie_chart, bar_chart = gr.Plot(), gr.Plot()\n",
        "            with gr.Row(): line_chart = gr.Plot()\n",
        "            gr.Markdown(\"## ü§ñ Chat with Your AI Expense Analyst\")\n",
        "            chatbot = gr.Chatbot(height=300)\n",
        "            chat_input = gr.Textbox(label=\"Your Question\")\n",
        "            chat_table_output = gr.DataFrame(interactive=False, label=\"Query Result\")\n",
        "            chat_input.submit(rag_chat_enhanced, inputs=[chat_input, chatbot], outputs=[chatbot, chat_table_output, chat_input])\n",
        "\n",
        "    all_outputs = [expense_df_display, total_spend_card, avg_txn_card, pie_chart, bar_chart, line_chart, budget_alerts_box]\n",
        "    add_manual_btn.click(lambda t, a, c, d: add_expense(t, a, c, d), [m_text, m_amount, m_cat, m_date], all_outputs)\n",
        "    add_voice_btn.click(add_expense_voice, [mic_audio], all_outputs)\n",
        "\n",
        "    def on_select_row(df: pd.DataFrame, evt: gr.SelectData):\n",
        "        if not evt.value: return \"\", \"\", \"\", \"\", \"\"\n",
        "        selected_row = df.iloc[evt.index[0]]\n",
        "        return selected_row['id'], pd.to_datetime(selected_row['date']).strftime('%Y-%m-%d'), selected_row['category'], selected_row['amount'], selected_row['text']\n",
        "\n",
        "    expense_df_display.select(on_select_row, [expense_df_display], [edit_id, edit_date, edit_cat, edit_amount, edit_text])\n",
        "    update_btn.click(update_expense, [edit_id, edit_date, edit_cat, edit_amount, edit_text], all_outputs)\n",
        "    delete_btn.click(delete_expense, [edit_id], [*all_outputs, edit_id, edit_date, edit_cat, edit_amount, edit_text])\n",
        "    set_budget_btn.click(set_budget, [b_category, b_amount], [current_budgets_df]).then(refresh_all_components, None, all_outputs)\n",
        "    demo.load(refresh_all_components, None, all_outputs)\n"
      ],
      "metadata": {
        "id": "vXFm8-Y1OltQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the app"
      ],
      "metadata": {
        "id": "N0f6auPNOzcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=False, share=True)"
      ],
      "metadata": {
        "id": "K1SnK7pqOzvD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}